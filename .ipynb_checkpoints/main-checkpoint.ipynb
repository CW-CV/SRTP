{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于文心大模型的智能阅卷数字人"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.PaddleOCR手写体检测与识别"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 安装相关依赖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T04:25:23.375947Z",
     "iopub.status.busy": "2025-03-09T04:25:23.375279Z",
     "iopub.status.idle": "2025-03-09T04:25:39.637885Z",
     "shell.execute_reply": "2025-03-09T04:25:39.636968Z",
     "shell.execute_reply.started": "2025-03-09T04:25:23.375885Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirror.baidu.com/pypi/simple/, https://mirrors.aliyun.com/pypi/simple/\r\n",
      "Collecting shapely (from -r PaddleOCR/requirements.txt (line 1))\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/d6/f3/c9cc07a7a03b5f5e83bd059f9adf3e21cf086b0e41d7f95e6464b151e798/shapely-2.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting scikit-image (from -r PaddleOCR/requirements.txt (line 2))\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/96/08/916e7d9ee4721031b2f625db54b11d8379bd51707afaa3e5a29aecf10bc4/scikit_image-0.25.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.8 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.8/14.8 MB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\r\n",
      "\u001b[?25hCollecting pyclipper (from -r PaddleOCR/requirements.txt (line 3))\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/84/a4/3e304f6c0d000382cd54d4a1e5f0d8fc28e1ae97413a2ec1016a7b840319/pyclipper-1.3.0.post6-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (912 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m912.2/912.2 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting lmdb (from -r PaddleOCR/requirements.txt (line 4))\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/75/78/2e04a41f12e8def7c9fa519e68b9cfd2554f030fbada24d747f9f9fe76d4/lmdb-1.6.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (294 kB)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from -r PaddleOCR/requirements.txt (line 5)) (4.67.1)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from -r PaddleOCR/requirements.txt (line 6)) (1.26.4)\r\n",
      "Collecting rapidfuzz (from -r PaddleOCR/requirements.txt (line 7))\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/15/6f/5211f2e80d4e82ff793f214429cbc8a8a69ef7978fd299112ae1c5595ae8/rapidfuzz-3.12.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: opencv-python in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from -r PaddleOCR/requirements.txt (line 8)) (4.10.0.84)\r\n",
      "Collecting opencv-contrib-python (from -r PaddleOCR/requirements.txt (line 9))\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/f7/13/756b13b8d5d417a0b4c3bf6ceafb59df0ed05cec7fedc2490bbbf5e60ebc/opencv_contrib_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (69.1 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\r\n",
      "\u001b[?25hCollecting cython (from -r PaddleOCR/requirements.txt (line 10))\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/dc/21/5b700dac60cc7af4261c7fa2e91f55fe5f38f6c183e1201ced7cc932201b/Cython-3.0.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: Pillow in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from -r PaddleOCR/requirements.txt (line 11)) (10.4.0)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from -r PaddleOCR/requirements.txt (line 12)) (6.0.2)\r\n",
      "Requirement already satisfied: requests in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from -r PaddleOCR/requirements.txt (line 13)) (2.32.3)\r\n",
      "Collecting albumentations (from -r PaddleOCR/requirements.txt (line 14))\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/97/d3/cf3aab593209d1be5e4bca54aeea297225708bd25f06426d6b8ec3630a76/albumentations-2.0.5-py3-none-any.whl (290 kB)\r\n",
      "Collecting albucore (from -r PaddleOCR/requirements.txt (line 16))\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/3d/de/4d9298befa6ae0f21230378f55100dca364816e3734028ca2766f2eca263/albucore-0.0.23-py3-none-any.whl (14 kB)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from -r PaddleOCR/requirements.txt (line 17)) (24.2)\r\n",
      "Requirement already satisfied: scipy>=1.11.4 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from scikit-image->-r PaddleOCR/requirements.txt (line 2)) (1.14.1)\r\n",
      "Collecting networkx>=3.0 (from scikit-image->-r PaddleOCR/requirements.txt (line 2))\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/b9/54/dd730b32ea14ea797530a4479b2ed46a6fb250f682a9cfb997e968bf0261/networkx-3.4.2-py3-none-any.whl (1.7 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting imageio!=2.35.0,>=2.33 (from scikit-image->-r PaddleOCR/requirements.txt (line 2))\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/cb/bd/b394387b598ed84d8d0fa90611a90bee0adc2021820ad5729f7ced74a8e2/imageio-2.37.0-py3-none-any.whl (315 kB)\r\n",
      "Collecting tifffile>=2022.8.12 (from scikit-image->-r PaddleOCR/requirements.txt (line 2))\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/63/70/6f363ab13f9903557a567a4471a28ee231b962e34af8e1dd8d1b0f17e64e/tifffile-2025.2.18-py3-none-any.whl (226 kB)\r\n",
      "Collecting lazy-loader>=0.4 (from scikit-image->-r PaddleOCR/requirements.txt (line 2))\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/83/60/d497a310bde3f01cb805196ac61b7ad6dc5dcf8dce66634dc34364b20b4f/lazy_loader-0.4-py3-none-any.whl (12 kB)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from requests->-r PaddleOCR/requirements.txt (line 13)) (3.4.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from requests->-r PaddleOCR/requirements.txt (line 13)) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from requests->-r PaddleOCR/requirements.txt (line 13)) (2.3.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from requests->-r PaddleOCR/requirements.txt (line 13)) (2024.12.14)\r\n",
      "Collecting pydantic>=2.9.2 (from albumentations->-r PaddleOCR/requirements.txt (line 14))\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/f4/3c/8cc1cc84deffa6e25d2d0c688ebb80635dfdbf1dbea3e30c541c8cf4d860/pydantic-2.10.6-py3-none-any.whl (431 kB)\r\n",
      "Collecting opencv-python-headless>=4.9.0.80 (from albumentations->-r PaddleOCR/requirements.txt (line 14))\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/dd/5c/c139a7876099916879609372bfa513b7f1257f7f1a908b0bdc1c2328241b/opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50.0 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.0/50.0 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\r\n",
      "\u001b[?25hCollecting stringzilla>=3.10.4 (from albucore->-r PaddleOCR/requirements.txt (line 16))\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/d3/14/87033aea90a3194172b8d0de11c20bcc407398b8e73a271894f2b9e241fa/stringzilla-3.12.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl (304 kB)\r\n",
      "Collecting simsimd>=5.9.2 (from albucore->-r PaddleOCR/requirements.txt (line 16))\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/56/53/13629d84b95b9373b7ce1447c43fc09da448d521bfa93eb02a8806ec0a50/simsimd-6.2.1-cp310-cp310-manylinux_2_28_x86_64.whl (632 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m632.7/632.7 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: annotated-types>=0.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from pydantic>=2.9.2->albumentations->-r PaddleOCR/requirements.txt (line 14)) (0.7.0)\r\n",
      "Collecting pydantic-core==2.27.2 (from pydantic>=2.9.2->albumentations->-r PaddleOCR/requirements.txt (line 14))\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/32/90/3b15e31b88ca39e9e626630b4c4a1f5a0dfd09076366f4219429e6786076/pydantic_core-2.27.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4.12.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from pydantic>=2.9.2->albumentations->-r PaddleOCR/requirements.txt (line 14)) (4.12.2)\r\n",
      "Installing collected packages: stringzilla, simsimd, pyclipper, lmdb, tifffile, shapely, rapidfuzz, pydantic-core, opencv-python-headless, opencv-contrib-python, networkx, lazy-loader, imageio, cython, scikit-image, pydantic, albucore, albumentations\r\n",
      "  Attempting uninstall: pydantic-core\r\n",
      "    Found existing installation: pydantic_core 2.18.1\r\n",
      "    Uninstalling pydantic_core-2.18.1:\r\n",
      "\u001b[31mERROR: Could not install packages due to an OSError: [Errno 13] Permission denied: 'INSTALLER'\r\n",
      "Consider using the `--user` option or check the permissions.\r\n",
      "\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#!pip install -r PaddleOCR/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T04:25:45.062599Z",
     "iopub.status.busy": "2025-03-09T04:25:45.062168Z",
     "iopub.status.idle": "2025-03-09T04:25:52.777345Z",
     "shell.execute_reply": "2025-03-09T04:25:52.776645Z",
     "shell.execute_reply.started": "2025-03-09T04:25:45.062571Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -ydantic-core (/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages)\u001b[0m\u001b[33m\r\n",
      "\u001b[0mLooking in indexes: https://mirror.baidu.com/pypi/simple/, https://mirrors.aliyun.com/pypi/simple/\r\n",
      "Collecting paddleocr\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/f5/b8/b5ee34d6da98b69ae5483f5fb9170a4d83b998ad38462dd31dada007400b/paddleocr-2.10.0-py3-none-any.whl (2.4 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: shapely in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from paddleocr) (2.0.7)\r\n",
      "Collecting scikit-image (from paddleocr)\r\n",
      "  Using cached https://mirrors.aliyun.com/pypi/packages/96/08/916e7d9ee4721031b2f625db54b11d8379bd51707afaa3e5a29aecf10bc4/scikit_image-0.25.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.8 MB)\r\n",
      "Requirement already satisfied: pyclipper in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from paddleocr) (1.3.0.post6)\r\n",
      "Requirement already satisfied: lmdb in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from paddleocr) (1.6.2)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from paddleocr) (4.67.1)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from paddleocr) (1.26.4)\r\n",
      "Requirement already satisfied: rapidfuzz in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from paddleocr) (3.12.2)\r\n",
      "Requirement already satisfied: opencv-python in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from paddleocr) (4.10.0.84)\r\n",
      "Collecting opencv-contrib-python (from paddleocr)\r\n",
      "  Using cached https://mirrors.aliyun.com/pypi/packages/f7/13/756b13b8d5d417a0b4c3bf6ceafb59df0ed05cec7fedc2490bbbf5e60ebc/opencv_contrib_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (69.1 MB)\r\n",
      "Collecting cython (from paddleocr)\r\n",
      "  Using cached https://mirrors.aliyun.com/pypi/packages/dc/21/5b700dac60cc7af4261c7fa2e91f55fe5f38f6c183e1201ced7cc932201b/Cython-3.0.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\r\n",
      "Requirement already satisfied: Pillow in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from paddleocr) (10.4.0)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from paddleocr) (6.0.2)\r\n",
      "Collecting python-docx (from paddleocr)\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/3e/3d/330d9efbdb816d3f60bf2ad92f05e1708e4a1b9abe80461ac3444c83f749/python_docx-1.1.2-py3-none-any.whl (244 kB)\r\n",
      "Collecting beautifulsoup4 (from paddleocr)\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/f9/49/6abb616eb3cbab6a7cca303dc02fdf3836de2e0b834bf966a7f5271a34d8/beautifulsoup4-4.13.3-py3-none-any.whl (186 kB)\r\n",
      "Requirement already satisfied: fonttools>=4.24.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from paddleocr) (4.55.3)\r\n",
      "Collecting fire>=0.3.0 (from paddleocr)\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/6b/b6/82c7e601d6d3c3278c40b7bd35e17e82aa227f050aa9f66cb7b7fce29471/fire-0.7.0.tar.gz (87 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\r\n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from paddleocr) (2.32.3)\r\n",
      "Collecting albumentations (from paddleocr)\r\n",
      "  Using cached https://mirrors.aliyun.com/pypi/packages/97/d3/cf3aab593209d1be5e4bca54aeea297225708bd25f06426d6b8ec3630a76/albumentations-2.0.5-py3-none-any.whl (290 kB)\r\n",
      "Collecting albucore (from paddleocr)\r\n",
      "  Using cached https://mirrors.aliyun.com/pypi/packages/3d/de/4d9298befa6ae0f21230378f55100dca364816e3734028ca2766f2eca263/albucore-0.0.23-py3-none-any.whl (14 kB)\r\n",
      "Collecting termcolor (from fire>=0.3.0->paddleocr)\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/7f/be/df630c387a0a054815d60be6a97eb4e8f17385d5d6fe660e1c02750062b4/termcolor-2.5.0-py3-none-any.whl (7.8 kB)\r\n",
      "Requirement already satisfied: stringzilla>=3.10.4 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from albucore->paddleocr) (3.12.2)\r\n",
      "Requirement already satisfied: simsimd>=5.9.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from albucore->paddleocr) (6.2.1)\r\n",
      "Collecting opencv-python-headless>=4.9.0.80 (from albucore->paddleocr)\r\n",
      "  Using cached https://mirrors.aliyun.com/pypi/packages/dd/5c/c139a7876099916879609372bfa513b7f1257f7f1a908b0bdc1c2328241b/opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50.0 MB)\r\n",
      "Requirement already satisfied: scipy>=1.10.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from albumentations->paddleocr) (1.14.1)\r\n",
      "Collecting pydantic>=2.9.2 (from albumentations->paddleocr)\r\n",
      "  Using cached https://mirrors.aliyun.com/pypi/packages/f4/3c/8cc1cc84deffa6e25d2d0c688ebb80635dfdbf1dbea3e30c541c8cf4d860/pydantic-2.10.6-py3-none-any.whl (431 kB)\r\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4->paddleocr)\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/d1/c2/fe97d779f3ef3b15f05c94a2f1e3d21732574ed441687474db9d342a7315/soupsieve-2.6-py3-none-any.whl (36 kB)\r\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from beautifulsoup4->paddleocr) (4.12.2)\r\n",
      "Collecting lxml>=3.1.0 (from python-docx->paddleocr)\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/65/8e/590e20833220eac55b6abcde71d3ae629d38ac1c3543bcc2bfe1f3c2f5d1/lxml-5.3.1-cp310-cp310-manylinux_2_28_x86_64.whl (5.2 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from requests->paddleocr) (3.4.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from requests->paddleocr) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from requests->paddleocr) (2.3.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from requests->paddleocr) (2024.12.14)\r\n",
      "Collecting networkx>=3.0 (from scikit-image->paddleocr)\r\n",
      "  Using cached https://mirrors.aliyun.com/pypi/packages/b9/54/dd730b32ea14ea797530a4479b2ed46a6fb250f682a9cfb997e968bf0261/networkx-3.4.2-py3-none-any.whl (1.7 MB)\r\n",
      "Collecting imageio!=2.35.0,>=2.33 (from scikit-image->paddleocr)\r\n",
      "  Using cached https://mirrors.aliyun.com/pypi/packages/cb/bd/b394387b598ed84d8d0fa90611a90bee0adc2021820ad5729f7ced74a8e2/imageio-2.37.0-py3-none-any.whl (315 kB)\r\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from scikit-image->paddleocr) (2025.2.18)\r\n",
      "Requirement already satisfied: packaging>=21 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from scikit-image->paddleocr) (24.2)\r\n",
      "Collecting lazy-loader>=0.4 (from scikit-image->paddleocr)\r\n",
      "  Using cached https://mirrors.aliyun.com/pypi/packages/83/60/d497a310bde3f01cb805196ac61b7ad6dc5dcf8dce66634dc34364b20b4f/lazy_loader-0.4-py3-none-any.whl (12 kB)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from pydantic>=2.9.2->albumentations->paddleocr) (0.7.0)\r\n",
      "Collecting pydantic-core==2.27.2 (from pydantic>=2.9.2->albumentations->paddleocr)\r\n",
      "  Using cached https://mirrors.aliyun.com/pypi/packages/32/90/3b15e31b88ca39e9e626630b4c4a1f5a0dfd09076366f4219429e6786076/pydantic_core-2.27.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\r\n",
      "Building wheels for collected packages: fire\r\n",
      "  Building wheel for fire (setup.py) ... \u001b[?25ldone\r\n",
      "\u001b[?25h  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114249 sha256=4c5fe16be0f69ba9f01f6c895b86b9332e48f84134f3108a7733611936a784d9\r\n",
      "  Stored in directory: /home/aistudio/.cache/pip/wheels/b1/88/03/4566a7c17572c6a276f8fd4834a1a412ddc91fc7c5e177a1a0\r\n",
      "Successfully built fire\r\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ydantic-core (/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages)\u001b[0m\u001b[33m\r\n",
      "\u001b[0mInstalling collected packages: termcolor, soupsieve, pydantic-core, opencv-python-headless, opencv-contrib-python, networkx, lxml, lazy-loader, imageio, cython, scikit-image, python-docx, pydantic, fire, beautifulsoup4, albucore, albumentations, paddleocr\r\n",
      "  Attempting uninstall: pydantic-core\r\n",
      "    Found existing installation: pydantic_core 2.18.1\r\n",
      "    Uninstalling pydantic_core-2.18.1:\r\n",
      "\u001b[31mERROR: Could not install packages due to an OSError: [Errno 13] Permission denied: 'INSTALLER'\r\n",
      "Consider using the `--user` option or check the permissions.\r\n",
      "\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#!pip install paddleocr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 准备测试图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T07:44:56.749406Z",
     "iopub.status.busy": "2025-02-28T07:44:56.749069Z",
     "iopub.status.idle": "2025-02-28T07:44:58.448183Z",
     "shell.execute_reply": "2025-02-28T07:44:58.447468Z",
     "shell.execute_reply.started": "2025-02-28T07:44:56.749385Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /home/aistudio/ppocr_img.zip\r\n",
      "   creating: /home/aistudio/data/ppocr_img/\r\n",
      "  inflating: /home/aistudio/data/ppocr_img/.DS_Store  \r\n",
      "  inflating: /home/aistudio/data/__MACOSX/ppocr_img/._.DS_Store  \r\n",
      "   creating: /home/aistudio/data/ppocr_img/imgs/\r\n",
      "   creating: /home/aistudio/data/ppocr_img/imgs_en/\r\n",
      "   creating: /home/aistudio/data/ppocr_img/ch/\r\n",
      "   creating: /home/aistudio/data/ppocr_img/table/\r\n",
      "   creating: /home/aistudio/data/ppocr_img/fonts/\r\n",
      "   creating: /home/aistudio/data/ppocr_img/imgs_words/\r\n",
      "  inflating: /home/aistudio/data/__MACOSX/ppocr_img/._imgs_words  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs/ger_1.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs/ger_2.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs/00059985.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs/japan_2.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs/model_prod_flow_ch.png  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs/japan_1.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs/00056221.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs/00009282.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs/00057937.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs/12.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs/11.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs/french_0.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs/00111002.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs/korean_1.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs/00207393.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs/00077949.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs/00015504.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs/00006737.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs/1.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs/00018069.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs_en/img_10.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs_en/img_11.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs_en/img_12.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs_en/img623.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs_en/model_prod_flow_en.png  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs_en/img_195.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs_en/254.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/ch/ch.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/ch/word_1.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/table/tableocr_pipeline_en.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/table/tableocr_pipeline.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/table/paper-image.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/table/ppstructure.GIF  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/table/layout.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/table/result_text.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/table/result_all.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/table/pipeline.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/table/table.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/table/pipeline_en.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/table/1.png  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/fonts/latin.ttf  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/fonts/simfang.ttf  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/fonts/spanish.ttf  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/fonts/korean.ttf  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/fonts/telugu.ttf  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/fonts/marathi.ttf  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/fonts/chinese_cht.ttf  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/fonts/german.ttf  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/fonts/arabic.ttf  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/fonts/japan.ttc  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/fonts/persian.ttf  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/fonts/hindi.ttf  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/fonts/kannada.ttf  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/fonts/uyghur.ttf  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/fonts/cyrillic.ttf  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/fonts/tamil.ttf  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/fonts/french.ttf  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/fonts/nepali.ttf  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/fonts/urdu.ttf  \r\n",
      "   creating: /home/aistudio/data/ppocr_img/imgs_words/bulgarian/\r\n",
      "   creating: /home/aistudio/data/ppocr_img/imgs_words/korean/\r\n",
      "   creating: /home/aistudio/data/ppocr_img/imgs_words/russia/\r\n",
      "   creating: /home/aistudio/data/ppocr_img/imgs_words/serbian_cyrillic/\r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs_words/.DS_Store  \r\n",
      "  inflating: /home/aistudio/data/__MACOSX/ppocr_img/imgs_words/._.DS_Store  \r\n",
      "   creating: /home/aistudio/data/ppocr_img/imgs_words/hindi/\r\n",
      "   creating: /home/aistudio/data/ppocr_img/imgs_words/uyghur/\r\n",
      "   creating: /home/aistudio/data/ppocr_img/imgs_words/german/\r\n",
      "   creating: /home/aistudio/data/ppocr_img/imgs_words/ch/\r\n",
      "   creating: /home/aistudio/data/ppocr_img/imgs_words/chinese_traditional/\r\n",
      "   creating: /home/aistudio/data/ppocr_img/imgs_words/urdu/\r\n",
      "   creating: /home/aistudio/data/ppocr_img/imgs_words/telugu/\r\n",
      "   creating: /home/aistudio/data/ppocr_img/imgs_words/japan/\r\n",
      "   creating: /home/aistudio/data/ppocr_img/imgs_words/italian/\r\n",
      "   creating: /home/aistudio/data/ppocr_img/imgs_words/portuguese/\r\n",
      "   creating: /home/aistudio/data/ppocr_img/imgs_words/occitan/\r\n",
      "   creating: /home/aistudio/data/ppocr_img/imgs_words/french/\r\n",
      "   creating: /home/aistudio/data/ppocr_img/imgs_words/belarusian/\r\n",
      "   creating: /home/aistudio/data/ppocr_img/imgs_words/kannada/\r\n",
      "   creating: /home/aistudio/data/ppocr_img/imgs_words/spanish/\r\n",
      "   creating: /home/aistudio/data/ppocr_img/imgs_words/tamil/\r\n",
      "   creating: /home/aistudio/data/ppocr_img/imgs_words/persian/\r\n",
      "   creating: /home/aistudio/data/ppocr_img/imgs_words/en/\r\n",
      "   creating: /home/aistudio/data/ppocr_img/imgs_words/arabic/\r\n",
      "   creating: /home/aistudio/data/ppocr_img/imgs_words/ukranian/\r\n",
      "   creating: /home/aistudio/data/ppocr_img/imgs_words/marathi/\r\n",
      "   creating: /home/aistudio/data/ppocr_img/imgs_words/nepali/\r\n",
      "   creating: /home/aistudio/data/ppocr_img/imgs_words/serbian_latin/\r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs_words/bulgarian/bg_1.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs_words/bulgarian/bg_2.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs_words/korean/2.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs_words/korean/1.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs_words/russia/ru_2.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs_words/russia/ru_1.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs_words/serbian_cyrillic/rsc_1.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs_words/serbian_cyrillic/rsc_2.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs_words/hindi/hi_2.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs_words/hindi/hi_1.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs_words/uyghur/ug_1.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs_words/uyghur/ug_2.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs_words/german/1.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs_words/ch/word_5.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs_words/ch/word_4.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs_words/ch/word_3.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs_words/ch/word_2.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs_words/ch/word_1.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs_words/chinese_traditional/chinese_cht_2.png  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs_words/chinese_traditional/chinese_cht_1.png  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs_words/urdu/ur_1.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs_words/urdu/ur_2.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs_words/telugu/te_1.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs_words/telugu/te_2.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs_words/japan/1.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs_words/italian/it_1.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs_words/italian/it_2.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs_words/portuguese/pu_1.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs_words/portuguese/pu_2.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs_words/occitan/oc_1.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs_words/occitan/oc_2.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs_words/french/2.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs_words/french/1.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs_words/belarusian/be_2.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs_words/belarusian/be_1.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs_words/kannada/ka_2.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs_words/kannada/ka_1.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs_words/spanish/xi_2.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs_words/spanish/xi_1.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs_words/tamil/ta_2.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs_words/tamil/ta_1.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs_words/persian/fa_1.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs_words/persian/fa_2.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs_words/en/word_5.png  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs_words/en/word_4.png  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs_words/en/word_3.png  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs_words/en/word_2.png  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs_words/en/word_1.png  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs_words/arabic/ar_1.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs_words/arabic/ar_2.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs_words/ukranian/uk_2.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs_words/ukranian/uk_1.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs_words/marathi/mr_1.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs_words/marathi/mr_2.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs_words/nepali/ne_2.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs_words/nepali/ne_1.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs_words/serbian_latin/rs_2.jpg  \r\n",
      "  inflating: /home/aistudio/data/ppocr_img/imgs_words/serbian_latin/rs_1.jpg  \r\n"
     ]
    }
   ],
   "source": [
    "# 解压官方数据集\n",
    "#!unzip /home/aistudio/ppocr_img.zip -d /home/aistudio/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### （跳过）文本检测测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T08:26:00.715178Z",
     "iopub.status.busy": "2025-02-28T08:26:00.714845Z",
     "iopub.status.idle": "2025-02-28T08:26:01.372387Z",
     "shell.execute_reply": "2025-02-28T08:26:01.371882Z",
     "shell.execute_reply.started": "2025-02-28T08:26:00.715158Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download https://paddleocr.bj.bcebos.com/PP-OCRv4/chinese/ch_PP-OCRv4_det_infer.tar to C:\\Users\\c'w/.paddleocr/whl\\det\\ch\\ch_PP-OCRv4_det_infer\\ch_PP-OCRv4_det_infer.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 4780/4780 [00:01<00:00, 3415.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download https://paddleocr.bj.bcebos.com/PP-OCRv4/chinese/ch_PP-OCRv4_rec_infer.tar to C:\\Users\\c'w/.paddleocr/whl\\rec\\ch\\ch_PP-OCRv4_rec_infer\\ch_PP-OCRv4_rec_infer.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 10720/10720 [00:02<00:00, 5013.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download https://paddleocr.bj.bcebos.com/dygraph_v2.0/ch/ch_ppocr_mobile_v2.0_cls_infer.tar to C:\\Users\\c'w/.paddleocr/whl\\cls\\ch_ppocr_mobile_v2.0_cls_infer\\ch_ppocr_mobile_v2.0_cls_infer.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 2138/2138 [00:00<00:00, 4643.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025/03/14 17:04:59] ppocr DEBUG: Namespace(help='==SUPPRESS==', use_gpu=False, use_xpu=False, use_npu=False, use_mlu=False, use_gcu=False, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, gpu_id=0, image_dir=None, page_num=0, det_algorithm='DB', det_model_dir=\"C:\\\\Users\\\\c'w/.paddleocr/whl\\\\det\\\\ch\\\\ch_PP-OCRv4_det_infer\", det_limit_side_len=960, det_limit_type='max', det_box_type='quad', det_db_thresh=0.3, det_db_box_thresh=0.6, det_db_unclip_ratio=1.5, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, scales=[8, 16, 32], alpha=1.0, beta=1.0, fourier_degree=5, rec_algorithm='SVTR_LCNet', rec_model_dir=\"C:\\\\Users\\\\c'w/.paddleocr/whl\\\\rec\\\\ch\\\\ch_PP-OCRv4_rec_infer\", rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='E:\\\\env_pytorch\\\\lib\\\\site-packages\\\\paddleocr\\\\ppocr\\\\utils\\\\ppocr_keys_v1.txt', use_space_char=True, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0.5, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=False, cls_model_dir=\"C:\\\\Users\\\\c'w/.paddleocr/whl\\\\cls\\\\ch_ppocr_mobile_v2.0_cls_infer\", cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, sr_model_dir=None, sr_image_shape='3, 32, 128', sr_batch_num=1, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=False, total_process_num=1, process_id=0, benchmark=False, save_log_path='./log_output/', show_log=True, use_onnx=False, onnx_providers=False, onnx_sess_options=False, return_word_box=False, output='./output', table_max_len=488, table_algorithm='TableAttn', table_model_dir=None, merge_no_span_structure=True, table_char_dict_path=None, formula_algorithm='LaTeXOCR', formula_model_dir=None, formula_char_dict_path=None, formula_batch_num=1, layout_model_dir=None, layout_dict_path=None, layout_score_threshold=0.5, layout_nms_threshold=0.5, kie_algorithm='LayoutXLM', ser_model_dir=None, re_model_dir=None, use_visual_backbone=True, ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ocr_order_method=None, mode='structure', image_orientation=False, layout=True, table=True, formula=False, ocr=True, recovery=False, recovery_to_markdown=False, use_pdf2docx_api=False, invert=False, binarize=False, alphacolor=(255, 255, 255), lang='ch', det=True, rec=True, type='ocr', savefile=False, ocr_version='PP-OCRv4', structure_version='PP-StructureV2')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025/03/14 17:05:01] ppocr WARNING: Since the angle classifier is not initialized, it will not be used during the forward process\n",
      "[[43.0, 187.0], [145.0, 187.0], [145.0, 215.0], [43.0, 215.0]]\n",
      "[[14.0, 152.0], [823.0, 155.0], [823.0, 187.0], [14.0, 184.0]]\n",
      "[[19.0, 108.0], [820.0, 105.0], [820.0, 136.0], [19.0, 139.0]]\n",
      "[[44.0, 78.0], [193.0, 78.0], [193.0, 105.0], [44.0, 105.0]]\n",
      "[[24.0, 43.0], [819.0, 39.0], [819.0, 68.0], [24.0, 72.0]]\n",
      "[[34.0, 12.0], [612.0, 10.0], [612.0, 37.0], [34.0, 39.0]]\n"
     ]
    }
   ],
   "source": [
    "from paddleocr import PaddleOCR, draw_ocr\n",
    "\n",
    "ocr = PaddleOCR()  # 只需运行一次即可下载模型并将其加载到内存中\n",
    "img_path = 'test3.jpg'  # 设置测试图片的路径\n",
    "result = ocr.ocr(img_path, rec=False)  # 只进行文本检测，不进行文本识别\n",
    "for idx in range(len(result)):   # 打印检测框位置信息\n",
    "    res = result[idx]\n",
    "    for line in res:\n",
    "        print(line)\n",
    "\n",
    "# 显示结果\n",
    "from PIL import Image\n",
    "result = result[0]\n",
    "image = Image.open(img_path).convert('RGB')\n",
    "im_show = draw_ocr(image, result, txts=None, scores=None, font_path='/home/aistudio/PaddleOCR/doc/fonts/simfang.ttf')  # 绘制检测框\n",
    "im_show = Image.fromarray(im_show)\n",
    "im_show.save('result3.jpg')  # 保存图片"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### （跳过）文本检测与识别测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T05:29:51.889421Z",
     "iopub.status.busy": "2025-03-08T05:29:51.889013Z",
     "iopub.status.idle": "2025-03-08T05:29:51.932372Z",
     "shell.execute_reply": "2025-03-08T05:29:51.931832Z",
     "shell.execute_reply.started": "2025-03-08T05:29:51.889397Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025/03/14 17:07:27] ppocr DEBUG: Namespace(help='==SUPPRESS==', use_gpu=False, use_xpu=False, use_npu=False, use_mlu=False, use_gcu=False, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, gpu_id=0, image_dir=None, page_num=0, det_algorithm='DB', det_model_dir=\"C:\\\\Users\\\\c'w/.paddleocr/whl\\\\det\\\\ch\\\\ch_PP-OCRv4_det_infer\", det_limit_side_len=960, det_limit_type='max', det_box_type='quad', det_db_thresh=0.3, det_db_box_thresh=0.6, det_db_unclip_ratio=1.5, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, scales=[8, 16, 32], alpha=1.0, beta=1.0, fourier_degree=5, rec_algorithm='SVTR_LCNet', rec_model_dir=\"C:\\\\Users\\\\c'w/.paddleocr/whl\\\\rec\\\\ch\\\\ch_PP-OCRv4_rec_infer\", rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='E:\\\\env_pytorch\\\\lib\\\\site-packages\\\\paddleocr\\\\ppocr\\\\utils\\\\ppocr_keys_v1.txt', use_space_char=True, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0.5, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=False, cls_model_dir=\"C:\\\\Users\\\\c'w/.paddleocr/whl\\\\cls\\\\ch_ppocr_mobile_v2.0_cls_infer\", cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, sr_model_dir=None, sr_image_shape='3, 32, 128', sr_batch_num=1, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=False, total_process_num=1, process_id=0, benchmark=False, save_log_path='./log_output/', show_log=True, use_onnx=False, onnx_providers=False, onnx_sess_options=False, return_word_box=False, output='./output', table_max_len=488, table_algorithm='TableAttn', table_model_dir=None, merge_no_span_structure=True, table_char_dict_path=None, formula_algorithm='LaTeXOCR', formula_model_dir=None, formula_char_dict_path=None, formula_batch_num=1, layout_model_dir=None, layout_dict_path=None, layout_score_threshold=0.5, layout_nms_threshold=0.5, kie_algorithm='LayoutXLM', ser_model_dir=None, re_model_dir=None, use_visual_backbone=True, ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ocr_order_method=None, mode='structure', image_orientation=False, layout=True, table=True, formula=False, ocr=True, recovery=False, recovery_to_markdown=False, use_pdf2docx_api=False, invert=False, binarize=False, alphacolor=(255, 255, 255), lang='ch', det=True, rec=True, type='ocr', savefile=False, ocr_version='PP-OCRv4', structure_version='PP-StructureV2')\n",
      "[2025/03/14 17:07:28] ppocr DEBUG: dt_boxes num : 15, elapsed : 0.3174469470977783\n",
      "[2025/03/14 17:07:35] ppocr DEBUG: rec_res num  : 15, elapsed : 7.231063604354858\n",
      "[[[10.0, 8.0], [329.0, 5.0], [329.0, 25.0], [11.0, 28.0]], ('40.(1文先发展的展到于文在包等)，在会定致是文化句前的源是。', 0.590488612651825)]\n",
      "[[[6.0, 27.0], [320.0, 27.0], [320.0, 49.0], [6.0, 49.0]], ('具在发展的动力，推动了社会突解的发展，延进发有人点期久', 0.774696409702301)]\n",
      "[[[3.0, 53.0], [316.0, 49.0], [316.0, 70.0], [3.0, 74.0]], ('能企发携人确群交的力素，访问的方辟知，进行地方实践：', 0.6406452655792236)]\n",
      "[[[5.0, 76.0], [318.0, 73.0], [318.0, 93.0], [5.0, 97.0]], ('把握超作后，提出综后治理的方条，诸放托有凝，把程食与产', 0.6744742393493652)]\n",
      "[[[6.0, 94.0], [323.0, 94.0], [323.0, 117.0], [6.0, 117.0]], ('改过很多提量，最必是动)的改界强孤成治茫国持还', 0.5921653509140015)]\n",
      "[[[5.0, 117.0], [326.0, 120.0], [325.0, 140.0], [5.0, 137.0]], ('确的方向，进们交的梦系，空线与理论并季，推动了曲国地', 0.6660290360450745)]\n",
      "[[[25.0, 213.0], [324.0, 211.0], [325.0, 230.0], [25.0, 232.0]], ('2）①人的价值是创是的值对于礼会自域作支融，要主我们', 0.6407130360603333)]\n",
      "[[[6.0, 235.0], [332.0, 233.0], [332.0, 253.0], [6.0, 255.0]], ('零在劳动和事献中迎现人生仿值，在认身社会的线一中实现们', 0.7086849808692932)]\n",
      "[[[7.0, 261.0], [329.0, 256.0], [329.0, 273.0], [8.0, 278.0]], ('值，研础前分：②科数疫师生搞确秀，激约高放技术，下田', 0.5936834812164307)]\n",
      "[[[6.0, 281.0], [325.0, 277.0], [326.0, 296.0], [6.0, 300.0]], ('指成民，在系动中学致了生旨的价重：他为农品系确存心', 0.5802342295646667)]\n",
      "[[[7.0, 303.0], [332.0, 298.0], [332.0, 321.0], [8.0, 326.0]], ('理知，对先展进分书川，对社论的是在，遗行？的转化', 0.6447420716285706)]\n",
      "[[[8.0, 328.0], [325.0, 323.0], [326.0, 343.0], [9.0, 349.0]], ('为比在革系的入科技小师生坚持了人会创统一.了', 0.5944949388504028)]\n",
      "[[[7.0, 350.0], [331.0, 347.0], [331.0, 365.0], [7.0, 368.0]], ('活键道救书，为我们级的得，缘一个或身组后为土地上', 0.6436877250671387)]\n",
      "[[[6.0, 371.0], [169.0, 373.0], [168.0, 391.0], [6.0, 389.0]], ('的奖源，更欢）们的的纷一。', 0.6554012894630432)]\n"
     ]
    }
   ],
   "source": [
    "from paddleocr import PaddleOCR, draw_ocr\n",
    "\n",
    "ocr = PaddleOCR()  # 只需运行一次即可下载模型并将其加载到内存中\n",
    "img_path = 'test2.jpg'  # 设置测试图片的路径\n",
    "result = ocr.ocr(img_path, cls=False)  # 只进行文本检测和文本识别，不进行方向分类\n",
    "for idx in range(len(result)):   # 打印信息\n",
    "    res = result[idx]\n",
    "    for line in res:\n",
    "        print(line)\n",
    "\n",
    "# 显示结果\n",
    "from PIL import Image\n",
    "result = result[0]\n",
    "image = Image.open(img_path).convert('RGB')\n",
    "boxes = [line[0] for line in result]   # 检测框\n",
    "txts = [line[1][0] for line in result]  # 识别出的文本\n",
    "scores = [line[1][1] for line in result]  # 置信度\n",
    "im_show = draw_ocr(image, boxes, txts, scores, font_path='/home/aistudio/PaddleOCR/doc/fonts/simfang.ttf')  # 绘制检测框，显示文本和置信度\n",
    "im_show = Image.fromarray(im_show)\n",
    "im_show.save('result_add_2.jpg')  # 保存图片"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 文本检测采用默认，文本识别采用自己训练的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T10:02:48.281701Z",
     "iopub.status.busy": "2025-02-28T10:02:48.278847Z",
     "iopub.status.idle": "2025-02-28T10:02:49.422614Z",
     "shell.execute_reply": "2025-02-28T10:02:49.421867Z",
     "shell.execute_reply.started": "2025-02-28T10:02:48.281658Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /home/aistudio/rec_infer.zip\r\n",
      "   creating: /home/aistudio/infer/\r\n",
      "  inflating: /home/aistudio/infer/inference.pdmodel  \r\n",
      "  inflating: /home/aistudio/infer/inference.pdiparams  \r\n",
      "  inflating: /home/aistudio/infer/inference.pdiparams.info  \r\n"
     ]
    }
   ],
   "source": [
    "# 解压自己训练的模型（解压一次即可，后续无需解压）\n",
    "#!unzip /home/aistudio/rec_infer.zip -d /home/aistudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T04:26:28.570253Z",
     "iopub.status.busy": "2025-03-09T04:26:28.569862Z",
     "iopub.status.idle": "2025-03-09T04:26:28.593412Z",
     "shell.execute_reply": "2025-03-09T04:26:28.592716Z",
     "shell.execute_reply.started": "2025-03-09T04:26:28.570229Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\env_pytorch\\lib\\site-packages\\paddle\\utils\\cpp_extension\\extension_utils.py:711: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md\n",
      "  warnings.warn(warning_message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025/03/14 20:34:13] ppocr DEBUG: Namespace(help='==SUPPRESS==', use_gpu=False, use_xpu=False, use_npu=False, use_mlu=False, use_gcu=False, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, gpu_id=0, image_dir=None, page_num=0, det_algorithm='DB', det_model_dir=\"C:\\\\Users\\\\c'w/.paddleocr/whl\\\\det\\\\ch\\\\ch_PP-OCRv4_det_infer\", det_limit_side_len=960, det_limit_type='max', det_box_type='quad', det_db_thresh=0.3, det_db_box_thresh=0.6, det_db_unclip_ratio=1.5, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, scales=[8, 16, 32], alpha=1.0, beta=1.0, fourier_degree=5, rec_algorithm='SVTR_LCNet', rec_model_dir='/infer', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='E:\\\\env_pytorch\\\\lib\\\\site-packages\\\\paddleocr\\\\ppocr\\\\utils\\\\ppocr_keys_v1.txt', use_space_char=True, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0.5, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=False, cls_model_dir=\"C:\\\\Users\\\\c'w/.paddleocr/whl\\\\cls\\\\ch_ppocr_mobile_v2.0_cls_infer\", cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, sr_model_dir=None, sr_image_shape='3, 32, 128', sr_batch_num=1, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=False, total_process_num=1, process_id=0, benchmark=False, save_log_path='./log_output/', show_log=True, use_onnx=False, onnx_providers=False, onnx_sess_options=False, return_word_box=False, output='./output', table_max_len=488, table_algorithm='TableAttn', table_model_dir=None, merge_no_span_structure=True, table_char_dict_path=None, formula_algorithm='LaTeXOCR', formula_model_dir=None, formula_char_dict_path=None, formula_batch_num=1, layout_model_dir=None, layout_dict_path=None, layout_score_threshold=0.5, layout_nms_threshold=0.5, kie_algorithm='LayoutXLM', ser_model_dir=None, re_model_dir=None, use_visual_backbone=True, ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ocr_order_method=None, mode='structure', image_orientation=False, layout=True, table=True, formula=False, ocr=True, recovery=False, recovery_to_markdown=False, use_pdf2docx_api=False, invert=False, binarize=False, alphacolor=(255, 255, 255), lang='ch', det=True, rec=True, type='ocr', savefile=False, ocr_version='PP-OCRv4', structure_version='PP-StructureV2')\n",
      "[2025/03/14 20:34:14] ppocr WARNING: Since the angle classifier is not initialized, it will not be used during the forward process\n",
      "[2025/03/14 20:34:15] ppocr DEBUG: dt_boxes num : 6, elapsed : 0.781562089920044\n",
      "[2025/03/14 20:34:20] ppocr DEBUG: rec_res num  : 6, elapsed : 5.453551292419434\n",
      "[[[34.0, 12.0], [612.0, 10.0], [612.0, 37.0], [34.0, 39.0]], ('①农业劳动充满综合的人性”，有助于培育完整的人。', 0.9301883578300476)]\n",
      "[[[24.0, 43.0], [819.0, 39.0], [819.0, 68.0], [24.0, 72.0]], ('②提供与自然和农业接触的机会，存留与自然和谐相处、巧用自然规律', 0.9454553723335266)]\n",
      "[[[44.0, 78.0], [193.0, 78.0], [193.0, 105.0], [44.0, 105.0]], ('的发展理念。', 0.9661561846733093)]\n",
      "[[[19.0, 108.0], [820.0, 105.0], [820.0, 136.0], [19.0, 139.0]], ('③传承农业生产生活经验，留存现代生活状态与过往生活方式的联系。', 0.9614974856376648)]\n",
      "[[[14.0, 152.0], [823.0, 155.0], [823.0, 187.0], [14.0, 184.0]], ('④建立人和土地的联系，维持有机循环，在现代与城市背景下强化土', 0.9827286601066589)]\n",
      "[[[43.0, 187.0], [145.0, 187.0], [145.0, 215.0], [43.0, 215.0]], ('地情结。', 0.9484618306159973)]\n",
      "①农业劳动充满综合的人性”，有助于培育完整的人。②提供与自然和农业接触的机会，存留与自然和谐相处、巧用自然规律的发展理念。③传承农业生产生活经验，留存现代生活状态与过往生活方式的联系。④建立人和土地的联系，维持有机循环，在现代与城市背景下强化土地情结。\n",
      "字符串已成功写入到 test3.txt\n"
     ]
    }
   ],
   "source": [
    "from paddleocr import PaddleOCR, draw_ocr\n",
    "\n",
    "ocr = PaddleOCR( rec_model_dir='/infer')  # 设置自己训练的模型的路径，模型路径下必须含有model和params文件\n",
    "img_path = 'test3.jpg'   # 设置测试图片的路径\n",
    "result = ocr.ocr(img_path, cls=True)    # 进行文本检测、方向分类和文本识别\n",
    "for idx in range(len(result)):  # 打印信息\n",
    "    res = result[idx]\n",
    "    for line in res:\n",
    "        print(line)\n",
    "\n",
    "\"\"\"\n",
    "显示结果\n",
    "\"\"\"\n",
    "from PIL import Image\n",
    "result = result[0]\n",
    "image = Image.open(img_path).convert('RGB')\n",
    "boxes = [line[0] for line in result]  # 检测框\n",
    "txts = [line[1][0] for line in result]  # 识别出的文本\n",
    "scores = [line[1][1] for line in result]  # 置信度\n",
    "combined_txts = ''.join(txts)  # 将识别出的文本组合到一起\n",
    "\n",
    "# 打印组合文本\n",
    "print(combined_txts)\n",
    "\n",
    "# 将组合文本存入txt文件\n",
    "file_name = \"test3.txt\"  # 定义txt文件的名称\n",
    "# 使用with语句打开文件，以写入模式('w')打开\n",
    "# 'w'模式会覆盖文件内容，如果文件不存在则创建新文件\n",
    "# 如果想在文件已存在时追加内容，而不是覆盖，可以将模式从'w'改为'a'\n",
    "with open(file_name, 'w', encoding='utf-8') as file:\n",
    "    # 将组合文本写入文件\n",
    "    file.write(combined_txts)\n",
    "# 提示写入完成\n",
    "print(f\"字符串已成功写入到 {file_name}\")\n",
    "\n",
    "# 显示图片结果\n",
    "#im_show = draw_ocr(image, boxes, txts, scores, font_path='/home/aistudio/PaddleOCR/doc/fonts/simfang.ttf')  # 绘制检测框，显示文本和置信度\n",
    "#im_show = Image.fromarray(im_show)\n",
    "#im_show.save('result_self_1.jpg')  # 保存图片"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.文心大模型评阅\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ERNIE Bot简介\n",
    "\n",
    "ERNIE Bot是文心&飞桨官方提供的Python库，提供便捷易用的Python接口，可调用文心大模型能力，完成包含文本创作、通用对话、语义向量、AI作图在内的多项任务。\n",
    "\n",
    "ERNIE Bot代码在GitHub上开源，欢迎大家进入[项目主页](https://github.com/PaddlePaddle/ERNIE-SDK)查看源码和使用文档，如果遇到问题也可以提出issue。\n",
    "\n",
    "下图是基于ERNIE Bot开发的Gradio演示应用程序，大家可以在[AI Studio应用中心](https://aistudio.baidu.com/application/detail/7545)在线体验。\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/34d8522114d34189af8054fdf34d9545d0c1d899963b4257a8bd66175e98f6a2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 安装ERNIE Bot\n",
    "\n",
    "使用pip可以快速安装ERNIE Bot，这里安装0.5.0版本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T06:34:06.961864Z",
     "iopub.status.busy": "2025-03-08T06:34:06.961513Z",
     "iopub.status.idle": "2025-03-08T06:34:08.410856Z",
     "shell.execute_reply": "2025-03-08T06:34:08.410238Z",
     "shell.execute_reply.started": "2025-03-08T06:34:06.961843Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirror.baidu.com/pypi/simple/, https://mirrors.aliyun.com/pypi/simple/\r\n",
      "Collecting erniebot==0.5.0\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/10/76/606de42bed0a03263e2d625f484f378673c386fcfe5997700355ebf95ec3/erniebot-0.5.0-py3-none-any.whl (65 kB)\r\n",
      "Requirement already satisfied: aiohttp in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from erniebot==0.5.0) (3.11.11)\r\n",
      "Requirement already satisfied: bce-python-sdk in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from erniebot==0.5.0) (0.9.25)\r\n",
      "Requirement already satisfied: colorlog in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from erniebot==0.5.0) (6.9.0)\r\n",
      "Requirement already satisfied: jsonschema>=4.19 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from erniebot==0.5.0) (4.23.0)\r\n",
      "Requirement already satisfied: requests>=2.20 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from erniebot==0.5.0) (2.32.3)\r\n",
      "Collecting tenacity (from erniebot==0.5.0)\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/b6/cb/b86984bed139586d01532a587464b5805f12e397594f19f931c4c2fbfa61/tenacity-9.0.0-py3-none-any.whl (28 kB)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from erniebot==0.5.0) (4.12.2)\r\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from jsonschema>=4.19->erniebot==0.5.0) (24.3.0)\r\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from jsonschema>=4.19->erniebot==0.5.0) (2024.10.1)\r\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from jsonschema>=4.19->erniebot==0.5.0) (0.35.1)\r\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from jsonschema>=4.19->erniebot==0.5.0) (0.22.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from requests>=2.20->erniebot==0.5.0) (3.4.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from requests>=2.20->erniebot==0.5.0) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from requests>=2.20->erniebot==0.5.0) (2.3.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from requests>=2.20->erniebot==0.5.0) (2024.12.14)\r\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from aiohttp->erniebot==0.5.0) (2.4.4)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from aiohttp->erniebot==0.5.0) (1.3.2)\r\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from aiohttp->erniebot==0.5.0) (5.0.1)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from aiohttp->erniebot==0.5.0) (1.5.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from aiohttp->erniebot==0.5.0) (6.1.0)\r\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from aiohttp->erniebot==0.5.0) (0.2.1)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from aiohttp->erniebot==0.5.0) (1.18.3)\r\n",
      "Requirement already satisfied: pycryptodome>=3.8.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from bce-python-sdk->erniebot==0.5.0) (3.21.0)\r\n",
      "Requirement already satisfied: future>=0.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from bce-python-sdk->erniebot==0.5.0) (1.0.0)\r\n",
      "Requirement already satisfied: six>=1.4.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from bce-python-sdk->erniebot==0.5.0) (1.17.0)\r\n",
      "Installing collected packages: tenacity, erniebot\r\n",
      "Successfully installed erniebot-0.5.0 tenacity-9.0.0\r\n"
     ]
    }
   ],
   "source": [
    "#1.安装ERNIE Bot\n",
    "#!pip install erniebot==0.5.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 认证鉴权\n",
    "\n",
    "调用文心大模型功能是收费服务，所以使用ERNIE Bot需要认证鉴权。 \n",
    "\n",
    "ERNIE Bot认证鉴权主要是设置后端和access token，分别通过`api_type`和`access_token`参数来指定。\n",
    "\n",
    "此处，我们使用`aistudio`后端。在AI Studio个人中心的[访问令牌页面](https://aistudio.baidu.com/usercenter/token)，大家可以获取`aistudio`后端的access token，然后填入下面代码中（替换`{YOUR-ACCESS-TOKEN}`）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T06:34:13.267888Z",
     "iopub.status.busy": "2025-03-08T06:34:13.267528Z",
     "iopub.status.idle": "2025-03-08T06:34:13.431116Z",
     "shell.execute_reply": "2025-03-08T06:34:13.430191Z",
     "shell.execute_reply.started": "2025-03-08T06:34:13.267865Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#2.认证鉴权\n",
    "import erniebot\n",
    "\n",
    "erniebot.api_type = 'aistudio'\n",
    "erniebot.access_token = '48b27a1e9b01529229e08de0d57ba7d9f907a03d'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请注意：\n",
    "\n",
    "- 不同后端的access token获取方式不同，特定后端获取的access token无法用于其他后端的认证鉴权。\n",
    "- access token是私密信息，切记不要对外公开。\n",
    "- `aistudio`后端的access token对应大家的个人账户，目前每个账户有100万token的免费额度，可以用于ERNIE Bot调用文心大模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 开始调用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T06:34:18.316181Z",
     "iopub.status.busy": "2025-03-08T06:34:18.315865Z",
     "iopub.status.idle": "2025-03-08T06:34:18.320525Z",
     "shell.execute_reply": "2025-03-08T06:34:18.320097Z",
     "shell.execute_reply.started": "2025-03-08T06:34:18.316160Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件内容已成功读入字符串变量：\n",
      "①农业劳动充满综合的人性”，有助于培育完整的人。②提供与自然和农业接触的机会，存留与自然和谐相处、巧用自然规律的发展理念。③传承农业生产生活经验，留存现代生活状态与过往生活方式的联系。④建立人和土地的联系，维持有机循环，在现代与城市背景下强化土地情结。\n"
     ]
    }
   ],
   "source": [
    "\"\"\"读取txt文件中的组合文本\"\"\"\n",
    "\n",
    "# 定义文件的名称\n",
    "file_name = \"test3.txt\"\n",
    "\n",
    "# 初始化一个空字符串变量，用于存储文件内容\n",
    "combined_txts = \"\"\n",
    " \n",
    "# 使用with语句打开文件，以读取模式('r')打开\n",
    "with open(file_name, 'r', encoding='utf-8') as file:\n",
    "    # 读取文件的整个内容\n",
    "    combined_txts = file.read()\n",
    " \n",
    "# 打印读取的内容\n",
    "print(\"文件内容已成功读入字符串变量：\")\n",
    "print(combined_txts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T06:34:38.091498Z",
     "iopub.status.busy": "2025-03-08T06:34:38.091160Z",
     "iopub.status.idle": "2025-03-08T06:35:00.561517Z",
     "shell.execute_reply": "2025-03-08T06:35:00.560981Z",
     "shell.execute_reply.started": "2025-03-08T06:34:38.091474Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "这道题目要求考生探讨农业劳动的意义，从多个角度进行分析。现在我们来逐一看看考生的回答是否准确、全面地回答了这个问题。\n",
      "\n",
      "首先，考生提到“农业劳动充满综合的人性，有助于培育完整的人”。这一点触及了农业劳动对人格培养的作用，是一个有深度的观点，符合题目要求探讨农业劳动的意义。\n",
      "\n",
      "其次，考生提到“提供与自然和农业接触的机会，存留与自然和谐相处、巧用自然规律的发展理念”。这里考生强调了农业劳动对于人与自然关系的促进作用，以及对于可持续发展理念的传承，这也是农业劳动的重要意义之一。\n",
      "\n",
      "接着，考生提到“传承农业生产生活经验，留存现代生活状态与过往生活方式的联系”。这一点突出了农业劳动在文化传承方面的作用，说明了它如何连接过去与现在，体现了农业劳动的历史和文化价值。\n",
      "\n",
      "最后，考生提到“建立人和土地的联系，维持有机循环，在现代与城市背景下强化土地情结”。这里考生关注的是农业劳动如何加深人与土地的情感联系，以及在现代城市化进程中如何保持这种联系，这也是对农业劳动意义的重要阐述。\n",
      "\n",
      "综合来看，考生的回答涵盖了农业劳动在人格培养、人与自然关系、文化传承以及人与土地情感联系等多个方面的意义，观点全面且深入，符合题目要求。\n",
      "\n",
      "因此，我认为该考生应得到满分6分。\n"
     ]
    }
   ],
   "source": [
    "#3.开始调用\n",
    "model = 'ernie-4.0'\n",
    "question = \"农业劳动有何意义？\"\n",
    "answer = combined_txts\n",
    "score = 6\n",
    "dialog = f\"考试题目为：{question}，考生作答内容为：{combined_txts}。该题满分为{score}分，应打多少分？\"\n",
    "messages = [{'role': 'user', 'content':dialog}]\n",
    "system = \"你是一个阅卷人\"\n",
    "first_response = erniebot.ChatCompletion.create(\n",
    "    model = model,\n",
    "    messages = messages,\n",
    "    system = system,\n",
    "    top_p = 0.5,\n",
    "    temperature = 0.5,\n",
    "    stream = True,\n",
    ")\n",
    "for response in first_response:\n",
    "    print(response.get_result(), end='', flush=True)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 以上代码调用`erniebot.ChatCompletion.create` API，发起对话补全请求，并打印模型的响应结果。\n",
    "\n",
    "2. 我们通过`model`参数指定使用ernie-4.0模型，通过`messages`参数指定给大模型的输入消息。在以上代码中，我们只进行单轮对话，因此`messages`列表中只包含一个元素。`messages`中的每一项都是一个字典，其中的`'role': 'user'`表示发出当前消息的角色是“用户”（也就是我们），`'content'`则对应消息的具体内容。另一个有用的参数是`system`，该参数可用于设定模型的行为，例如给予模型人设或是要求模型以特定格式回答问题。\n",
    "\n",
    "3. ERNIE Bot支持设定`top_p`和`temperature`参数，影响模型在采样过程中的行为，进而控制模型响应结果的多样性。通常来说，`top_p`和`temperature`参数**只需要设置其中一个即可**。设置`top_p`参数可以使生成的token从概率和恰好达到或超过`top_p`的token集合中采样得到。设置`top_p`参数时需注意以下几点：\n",
    "（1）`top_p`影响生成文本的多样性，取值越大，生成文本的多样性越强；（2）`top_p`的默认取值为`0.8`，取值范围为`[0, 1.0]`。`temperature`参数也用于控制采样的随机性。设置`temperature`参数需要注意如下几点：（1）较高的`temperature`会使生成结果更加随机，而较低的数值会使结果更加集中和确定；（2）`temperature`的默认取值为`0.95`，取值范围为`(0, 1.0]`，不能为`0`。\n",
    "\n",
    "4. 为了减少用户的等待时间，ERNIE Bot支持流式传输数据，即能够“实时”地获取模型响应，而不需要等待全部内容生成完毕。具体而言，为`erniebot.ChatCompletion.create` API传入参数`stream=True`，则API将返回一个生成器。这个生成器对应一个响应序列，我们通过迭代操作即可获取全部响应。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_pytorch",
   "language": "python",
   "name": "env_pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
